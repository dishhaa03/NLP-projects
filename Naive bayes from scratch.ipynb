{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcadb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from math import log\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53358d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Just plan boarding\", \"negative\"),\n",
    "    (\"entirely predictable & lack energy\", \"negative\"),\n",
    "    (\"no surprises & very few laughs\", \"negative\"),\n",
    "    (\"Very powerful\", \"positive\"),\n",
    "    (\"the mist fun films of the summer\", \"positive\"),\n",
    "    (\"Chinese Beijing Chinese\", \"C\"),\n",
    "    (\"Chinese Chinese Shangai\", \"C\"),\n",
    "    (\"Chinese Macao\", \"C\"),\n",
    "    (\"Tokyo japan Chinese\", \"J\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b18db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    return words    # spliting the words\n",
    "\n",
    "class_word_counts = defaultdict(lambda: defaultdict(int))   # empty dict\n",
    "class_counts = defaultdict(int)\n",
    "vocabulary = set()   # empty set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48dea234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shangai', 'the', 'films', 'fun', 'no', 'powerful', 'laughs', 'boarding', 'lack', 'just', 'of', 'plan', 'summer', 'predictable', 'chinese', 'energy', 'mist', 'macao', 'japan', 'tokyo', 'very', 'few', 'beijing', 'entirely', 'surprises'}\n",
      "defaultdict(<function <lambda> at 0x000001BEA7337B80>, {'negative': defaultdict(<class 'int'>, {'just': 1, 'plan': 1, 'boarding': 1, 'entirely': 1, 'predictable': 1, 'lack': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 1, 'few': 1, 'laughs': 1}), 'positive': defaultdict(<class 'int'>, {'very': 1, 'powerful': 1, 'the': 2, 'mist': 1, 'fun': 1, 'films': 1, 'of': 1, 'summer': 1}), 'C': defaultdict(<class 'int'>, {'chinese': 5, 'beijing': 1, 'shangai': 1, 'macao': 1}), 'J': defaultdict(<class 'int'>, {'tokyo': 1, 'japan': 1, 'chinese': 1})})\n",
      "{'negative': 0.3333333333333333, 'positive': 0.2222222222222222, 'C': 0.3333333333333333, 'J': 0.1111111111111111}\n"
     ]
    }
   ],
   "source": [
    "for text, label in data:\n",
    "    words = preprocess(text)  # spliting the words\n",
    "    class_counts[label] += 1\n",
    "    for word in words:\n",
    "        vocabulary.add(word)     #counting of vacabulary for entire dataset\n",
    "        class_word_counts[label][word] += 1   #count occurence of each word  \n",
    "        \n",
    "#print(word)\n",
    "print(vocabulary)\n",
    "print(class_word_counts)\n",
    "\n",
    "total_samples = len(data)\n",
    "class_priors = {label: count / total_samples for label, count in class_counts.items()}\n",
    "print(class_priors)   # probability of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a889ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'negative': defaultdict(float,\n",
       "                         {'shangai': 0.03571428571428571,\n",
       "                          'the': 0.03571428571428571,\n",
       "                          'films': 0.03571428571428571,\n",
       "                          'fun': 0.03571428571428571,\n",
       "                          'no': 0.07142857142857142,\n",
       "                          'powerful': 0.03571428571428571,\n",
       "                          'laughs': 0.07142857142857142,\n",
       "                          'boarding': 0.07142857142857142,\n",
       "                          'lack': 0.07142857142857142,\n",
       "                          'just': 0.07142857142857142,\n",
       "                          'of': 0.03571428571428571,\n",
       "                          'plan': 0.07142857142857142,\n",
       "                          'summer': 0.03571428571428571,\n",
       "                          'predictable': 0.07142857142857142,\n",
       "                          'chinese': 0.03571428571428571,\n",
       "                          'energy': 0.07142857142857142,\n",
       "                          'mist': 0.03571428571428571,\n",
       "                          'macao': 0.03571428571428571,\n",
       "                          'japan': 0.03571428571428571,\n",
       "                          'tokyo': 0.03571428571428571,\n",
       "                          'very': 0.07142857142857142,\n",
       "                          'few': 0.07142857142857142,\n",
       "                          'beijing': 0.03571428571428571,\n",
       "                          'entirely': 0.07142857142857142,\n",
       "                          'surprises': 0.07142857142857142}),\n",
       "             'positive': defaultdict(float,\n",
       "                         {'shangai': 0.037037037037037035,\n",
       "                          'the': 0.1111111111111111,\n",
       "                          'films': 0.07407407407407407,\n",
       "                          'fun': 0.07407407407407407,\n",
       "                          'no': 0.037037037037037035,\n",
       "                          'powerful': 0.07407407407407407,\n",
       "                          'laughs': 0.037037037037037035,\n",
       "                          'boarding': 0.037037037037037035,\n",
       "                          'lack': 0.037037037037037035,\n",
       "                          'just': 0.037037037037037035,\n",
       "                          'of': 0.07407407407407407,\n",
       "                          'plan': 0.037037037037037035,\n",
       "                          'summer': 0.07407407407407407,\n",
       "                          'predictable': 0.037037037037037035,\n",
       "                          'chinese': 0.037037037037037035,\n",
       "                          'energy': 0.037037037037037035,\n",
       "                          'mist': 0.07407407407407407,\n",
       "                          'macao': 0.037037037037037035,\n",
       "                          'japan': 0.037037037037037035,\n",
       "                          'tokyo': 0.037037037037037035,\n",
       "                          'very': 0.07407407407407407,\n",
       "                          'few': 0.037037037037037035,\n",
       "                          'beijing': 0.037037037037037035,\n",
       "                          'entirely': 0.037037037037037035,\n",
       "                          'surprises': 0.037037037037037035}),\n",
       "             'C': defaultdict(float,\n",
       "                         {'shangai': 0.07142857142857142,\n",
       "                          'the': 0.03571428571428571,\n",
       "                          'films': 0.03571428571428571,\n",
       "                          'fun': 0.03571428571428571,\n",
       "                          'no': 0.03571428571428571,\n",
       "                          'powerful': 0.03571428571428571,\n",
       "                          'laughs': 0.03571428571428571,\n",
       "                          'boarding': 0.03571428571428571,\n",
       "                          'lack': 0.03571428571428571,\n",
       "                          'just': 0.03571428571428571,\n",
       "                          'of': 0.03571428571428571,\n",
       "                          'plan': 0.03571428571428571,\n",
       "                          'summer': 0.03571428571428571,\n",
       "                          'predictable': 0.03571428571428571,\n",
       "                          'chinese': 0.21428571428571427,\n",
       "                          'energy': 0.03571428571428571,\n",
       "                          'mist': 0.03571428571428571,\n",
       "                          'macao': 0.07142857142857142,\n",
       "                          'japan': 0.03571428571428571,\n",
       "                          'tokyo': 0.03571428571428571,\n",
       "                          'very': 0.03571428571428571,\n",
       "                          'few': 0.03571428571428571,\n",
       "                          'beijing': 0.07142857142857142,\n",
       "                          'entirely': 0.03571428571428571,\n",
       "                          'surprises': 0.03571428571428571}),\n",
       "             'J': defaultdict(float,\n",
       "                         {'shangai': 0.038461538461538464,\n",
       "                          'the': 0.038461538461538464,\n",
       "                          'films': 0.038461538461538464,\n",
       "                          'fun': 0.038461538461538464,\n",
       "                          'no': 0.038461538461538464,\n",
       "                          'powerful': 0.038461538461538464,\n",
       "                          'laughs': 0.038461538461538464,\n",
       "                          'boarding': 0.038461538461538464,\n",
       "                          'lack': 0.038461538461538464,\n",
       "                          'just': 0.038461538461538464,\n",
       "                          'of': 0.038461538461538464,\n",
       "                          'plan': 0.038461538461538464,\n",
       "                          'summer': 0.038461538461538464,\n",
       "                          'predictable': 0.038461538461538464,\n",
       "                          'chinese': 0.07692307692307693,\n",
       "                          'energy': 0.038461538461538464,\n",
       "                          'mist': 0.038461538461538464,\n",
       "                          'macao': 0.038461538461538464,\n",
       "                          'japan': 0.07692307692307693,\n",
       "                          'tokyo': 0.07692307692307693,\n",
       "                          'very': 0.038461538461538464,\n",
       "                          'few': 0.038461538461538464,\n",
       "                          'beijing': 0.038461538461538464,\n",
       "                          'entirely': 0.038461538461538464,\n",
       "                          'surprises': 0.038461538461538464})})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_likelihoods = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in class_word_counts:\n",
    "    for word in vocabulary:\n",
    "        word_likelihoods[label][word] = (class_word_counts[label][word] + 1) / (class_counts[label] + len(vocabulary)) \n",
    "        #  smoothing factor  1 le rhe h \n",
    "word_likelihoods    # hr class me hr word ki probabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3695a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictable with no fun\n",
      "negative  :  -9.708931458073831\n",
      "positive  :  -10.698440814229317\n",
      "C  :  -11.095225819193722\n",
      "J  :  -11.971514191400665\n",
      "Text: 'predictable with no fun' - Predicted Label: negative\n",
      "\n",
      "Chinese Chinese Chinese Tokyo Japan\n",
      "negative  :  -17.75963483954413\n",
      "positive  :  -17.98326172679792\n",
      "C  :  -12.384356431859965\n",
      "J  :  -15.021971364643901\n",
      "Text: 'Chinese Chinese Chinese Tokyo Japan' - Predicted Label: C\n",
      "\n",
      "predicted classes are :  ['negative', 'C']\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    \"predictable with no fun\",\n",
    "    \"Chinese Chinese Chinese Tokyo Japan\"\n",
    "]  \n",
    "nb_preds_scratch=[]   # hum kya predict kr rhe h \n",
    "for text in test_data:\n",
    "    print(text)\n",
    "    words = preprocess(text)\n",
    "    max_posterior = -float('inf')\n",
    "    predicted_label = tuple()\n",
    "    for label in class_priors:\n",
    "        posterior = log(class_priors[label])\n",
    "        for word in words:\n",
    "            if word in word_likelihoods[label]:\n",
    "                posterior += log(word_likelihoods[label][word])\n",
    "        print(label, \" : \", posterior)\n",
    "        if posterior > max_posterior:\n",
    "            max_posterior = posterior\n",
    "            predicted_label = label\n",
    "    print(f\"Text: '{text}' - Predicted Label: {predicted_label}\"+\"\\n\")\n",
    "    nb_preds_scratch.append(predicted_label)\n",
    "    \n",
    "print(\"predicted classes are : \",nb_preds_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bccc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Just plan boarding', 'entirely predictable & lack energy', 'no surprises & very few laughs', 'Very powerful', 'the mist fun films of the summer', 'Chinese Beijing Chinese', 'Chinese Chinese Shangai', 'Chinese Macao', 'Tokyo japan Chinese')\n"
     ]
    }
   ],
   "source": [
    "sentences,labels = zip(*data)\n",
    "print(sentences)\n",
    "y_test = ('negative','C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85877e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b5e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Scratch Naive Bayes: 1.0\n",
      "Accuracy of scikit-learn Naive Bayes: 1.0\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(sentences)\n",
    "X_test_vec = vectorizer.transform(test_data)\n",
    "\n",
    "nb_model = MultinomialNB() #Train Multinomial Naive Bayes model\n",
    "nb_model.fit(X_train_vec, labels)\n",
    "\n",
    "nb_preds_sklearn = nb_model.predict(X_test_vec) # Make predictions\n",
    "\n",
    "\n",
    "accuracy_scratch = accuracy_score(y_test, nb_preds_scratch) # ye scratch se jo predict kiya\n",
    "\n",
    "accuracy_sklearn = accuracy_score(y_test, nb_preds_sklearn) # ye direct model se predict kiya\n",
    "\n",
    "print(\"Accuracy of Scratch Naive Bayes:\", accuracy_scratch)\n",
    "print(\"Accuracy of scikit-learn Naive Bayes:\", accuracy_sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
